---
tags:
  - note
  - 卒業研究
---
> [!IMPORTANT]
> [[企画書の書き方]]を参照の下、企画書を書くこと。
> 自己レビューの際は、[[企画書のレビュー基準]]を参照してください。
> タグ、noteルール追加は[[設計、運用ルール、タグ仕様]]へ。


## **SQLクエリ解析＋機械学習（NLP）によるDBスキーマ推定ツール開発**
- スキーマ推定の動的検索
	- ユーザーがクエリや条件を順に追加していく過程で、その都度スキーマの構造推定結果が変化・補完されていくようなインタラクティブな推定

## 🔧 技術仕様・構成案（Python＋SQL）

### 🔹 1. 入力情報

| 要素          | 内容                                                         |
| ----------- | ---------------------------------------------------------- |
| SQLクエリ群     | ユーザーが段階的に入力する `SELECT`, `JOIN`, `WHERE`, `GROUP BY` などのクエリ |
- 対象とするSQL文：
    - `SELECT`, `WITH`, `JOIN`, `GROUP BY`, `ORDER BY`, `INSERT`, `UPDATE`, `DELETE` …など **基本すべてのSQLに対応**
    - 特に「読み取り系」クエリ（SELECT）を主軸としつつ、他のクエリからも推定補助を行う
- クエリが1件ずつ投入される想定で、「ログ」に蓄積し、**スキーマ推定がその都度アップデートされる形式**

※現段階では、SQlite3を対象とする

---

### 🔹 2. スキーマ推定処理

#### A. クエリ解析（静的）

- Pythonの `sqlparse` などを使ってクエリをトークン化し、`SELECT`, `FROM`, `JOIN`, `ON`, `WHERE` 句を抽出。
- 各クエリから以下の情報を抽出し、構造推定に使用：
    - 使用テーブル名・結合条件・使用されたカラムの頻度
    - 結合回数が多いテーブルペア → 外部キー候補

#### B. 名称解析（NLP的処理）

- カラム名・テーブル名をスネークケース/キャメルケースなどで分割し、語幹を抽出。
- 例：`user_id` → ["user", "id"] / `purchaseDate` → ["purchase", "date"]
- WordNet, spaCy, gensim などで類義語・分類を参照し、意味的なクラスタリング（ユーザー系・商品系など）

#### C. 構造推定(結合からの解析＋名称解析)

- 推定対象：
    - 主キー / 外部キー候補
    - テーブル間の関係（E-R 図の線）
    - 属性のカテゴリ（例えば「time系」など）
- 構成方法：
    - 結合条件＋出現頻度ベースの信頼スコア
    - 名前類似度（意味的な距離）ベースの補完推定
    - 段階的に変化する「推定スキーマグラフ」を構築

---


### 3.  推定対象の粒度

|項目|内容|
|---|---|
|**テーブル名**|出現するテーブルの一覧・関係を把握|
|**カラム名**|各テーブルのカラム一覧を収集|
|**テーブル間接続**|`JOIN` 句や同時出現頻度から「関係の強さ」または「接続候補」可視化|
|**カラムの意味推定**|カラム名の語彙解析（NLP）による「これは何を表すのか」の自動分類（例：時間・ユーザー・商品・金額…）|
|**構造図出力**|構造をノード（テーブル/カラム）・エッジ（関係）として可視化（例：NetworkX + Matplotlib）|

→ 特に**要素間の接続**を明示することで、**DB初学者が構造を直感的に理解しやすいように支援**する目的を持つ。

### 🔹 4. インタラクティブな動的推定

- ユーザーが1つずつクエリを入力・追加 → 推定結果がリアルタイムで更新
- 各SQLクエリを「イベント」として順番に処理し、構造情報を蓄積・更新
- 実装的には：
    - `クエリ1件目` → 初期推定
    - `クエリ2件目以降` → 新情報が加わるたびにスキーマ構造が変化
- 差分として「新たに推定された接続」や「意味が変わったカラム」などを表示できるようにする
- 可能な仕様：
    - 「現在までのクエリから得られた構造」の可視化（テキストまたは簡易グラフ）
    - 次に使うと推定が明確になる「探索候補」表示

---

### 🔹 5. 出力・評価方法

- 出力例：
    - JSON形式の推定スキーマ情報
    - 表形式：テーブル間の関係候補、信頼スコア
    - ER図的なテーブルグラフ（matplotlib などを使用）
- 評価：
    - 既知スキーマ付きのDBに対して推定精度（F値、適合率/再現率）を計測
    - 推定の変化過程を記録し、「何クエリ目で何が見えてきたか」を分析



| 機能         | ライブラリ例                               |
| ---------- | ------------------------------------ |
| SQLパース     | `sqlparse`, `sqlglot`                |
| DB接続       | `sqlite3`, `psycopg2`, `SQLAlchemy`  |
| クエリ発行・ログ化  | 独自のPythonコードでログ保存                    |
| 可視化（グラフ）   | `networkx`, `matplotlib`, `graphviz` |
| NLP        | `spaCy`, `NLTK`, `gensim`, `re`      |
| Web UI（任意） | `Streamlit`, `Gradio`                |
|            |                                      |


## ⚙️ 実装方針（Python＋sqlite3）

### A. SQL解析エンジン

- `sqlglot`（SQL全対応レベルでの文法解析が強力）
- `sqlparse`（軽量でトークン化・句ごとの分離に便利）
- クエリをAST（構文木）にして分析し、以下を抽出：
    - 使用テーブル・カラム
    - `JOIN` や `ON` 条件（テーブル間接続の候補）
    - サブクエリ、WITH句、入れ子SELECTなども正確に追う

※AST……**ソースコードの構文解析に意味付けを行ったもの**
### B. 構造推定ロジック

- 各クエリに含まれる情報をメタ構造として蓄積：
    python
{
  "tables": {
    "users": {"columns": {"id", "name"}, "access_count": 4},
    "orders": {"columns": {"id", "user_id"}, "access_count": 3}
  },
  "connections": {
    ("users.id", "orders.user_id"): {"type": "join", "count": 3}
  }
}
- テーブルペアのJOIN条件から「外部キーらしさ」スコア推定（頻度・名称・型推定を統合）

### C. カラム名の意味推定（NLP要素）

- 前処理：
    - スネーク・キャメル・数字などを正規化し語幹抽出
- 意味クラスタ分類：
    - ルールベース＋WordNet/spaCy語彙分類などで、「time型」「ID系」「name系」「数値」「金額」などをクラスタ化
- 必要なら：
    - Word2Vecで類似語推定

---

##  出力・UIイメージ（CLI or Web）

- **CLI版**（初期開発）：
    - クエリを打ち込むたびに更新されたスキーマ候補を出力
    - `現在の構造`, `新たに判明した関係`, `カラムの意味クラスタ` を逐次表示
- **GUI/Web版**：
    - クエリ履歴＋可視化（構造グラフ）
    - 構造更新ログがサイドバーに表示されると直感
	    - UIでの構造差分の見せ方
			- グラフに「新規追加」要素だけ色をつけて表示
			- 追加したクエリが与えた影響の説明（「このJOINが新たな接続を作りました」など）
    - マウスオーバーで「このカラムは '時間系' と推定」などのヒントを表示するのもアリ

---

| 項目       | メモ                                        |
| -------- | ----------------------------------------- |
| 初期データベース | SQLite で軽めのサンプル                           |
| 開発ステップ   | ①SQL構文解析 → ②構造情報蓄積 → ③NLP意味分類 → ④可視化・ログ管理 |
| 評価方法     | 「正解スキーマ」との一致率を見る                          |
| ユーザーへの出力 | ER図風テーブル×カラムの一覧、JSON、グラフ                  |

---

## この研究の意義

- **新規性**：
    - クエリの逐次追加に応じてスキーマが変化・補完される動的推定のUI/UXを設計
- **有用性**：
    - 初学者やSQLに慣れていない人にとって、暗黙知になりやすいDB構造を「クエリベースで可視化」して理解支援
- **汎用性**：
    - どんなSQL文でも解析可能（サブクエリやWITH含む）
    - 実行ログにも流用可（Webサービスで得られる実ログ解析にも転用できる）
---

UI/UX最適化に寄る（類似研究との差分をインタラクティブ要素で見せるなら妥当）

## コード構造

schema_infer/
├── main.py                 # CLI/UIのエントリーポイント
├── sql_parser.py           # SQLの文法解析、構文木化
├── schema_store.py         # 現在のスキーマ情報の保持と更新
├── nlp_analyzer.py         # カラム名・テーブル名のNLP分類
├── visualizer.py           # 構造の可視化（NetworkXなど）
├── query_log.json          # クエリ履歴の保存（オプション）
├── config.py            # 意味分類ラベルやしきい値、パス定義など
├── db/
│   └── sample.db           # SQLite用のサンプルデータベース
└── output/
    └── schema_snapshot_001.json   # 構造推定のスナップショット


|モジュール|概要|
|---|---|
|`sql_parser.py`|クエリから「テーブル」「カラム」「JOIN条件」など抽出|
|`schema_store.py`|抽出情報を使ってスキーマ構造を保持・更新。過去との差分比較もここで|
|`nlp_analyzer.py`|テーブル名・カラム名の意味推定。語幹・語彙分類・クラスタ分けなど|
|`visualizer.py`|テーブル同士のつながりや意味ラベルをグラフで描画（NetworkXなど）|
|`main.py`|クエリ投入・ログ・表示の一括制御|


### インクリメンタル構造更新ログの扱い

- 「クエリ1件ごとに、スキーマ構造がどう変わったか」を記録・確認できるようにすること

###  ログの設計
クエリを追加するたびに、前回との差分を `JSON` などで出力：
ex)
{
  "query_id": 3,
  "query": "SELECT ...",
  "added_tables": ["products"],
  "added_columns": ["products.name", "order_items.product_id"],
  "new_connections": [
    {
      "from": "order_items.product_id",
      "to": "products.product_id",
      "type": "join",
      "confidence": 0.9
    }
  ]
}
このような「スナップショット or 差分ログ」を `output/` に番号付きで保存する。

### 🔸 差分検出の方法（`schema_store.py` ）

- `current_schema`（構造情報）と `previous_schema` を比較
- 差分の「追加・変更」部分だけ抽出
- ログフォーマットで記録＆ターミナルに表示